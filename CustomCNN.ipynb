{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27111cde",
   "metadata": {
    "papermill": {
     "duration": 16.550132,
     "end_time": "2023-11-24T06:17:08.283688",
     "exception": false,
     "start_time": "2023-11-24T06:16:51.733556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    GlobalAveragePooling2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef677ae",
   "metadata": {
    "papermill": {
     "duration": 0.015244,
     "end_time": "2023-11-24T06:17:08.306415",
     "exception": false,
     "start_time": "2023-11-24T06:17:08.291171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataset of fake real recognition\n",
    "train_path = './tranning'\n",
    "validation_path = './testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4dc60",
   "metadata": {
    "papermill": {
     "duration": 0.023358,
     "end_time": "2023-11-24T06:17:08.335241",
     "exception": false,
     "start_time": "2023-11-24T06:17:08.311883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# no. of classes in recognition data\n",
    "className = glob(train_path + \"/*\")\n",
    "NumberofClass = len(className)\n",
    "print(\"NumberofClass:\", NumberofClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8e032",
   "metadata": {
    "papermill": {
     "duration": 0.015316,
     "end_time": "2023-11-24T06:17:08.356107",
     "exception": false,
     "start_time": "2023-11-24T06:17:08.340791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data augumentation \n",
    "train_datagen = ImageDataGenerator(rescale=1/255)    \n",
    "validation_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edebf84",
   "metadata": {
    "papermill": {
     "duration": 0.075106,
     "end_time": "2023-11-24T06:17:08.436685",
     "exception": false,
     "start_time": "2023-11-24T06:17:08.361579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "# recognition data\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                  shear_range=0.3,\n",
    "                  horizontal_flip=True,\n",
    "                  zoom_range=0.3\n",
    "                  )\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                train_path,\n",
    "                target_size=(224,224),\n",
    "                batch_size=batch_size,\n",
    "                color_mode=\"rgb\",\n",
    "                class_mode=\"categorical\"\n",
    "                )\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "                validation_path,\n",
    "                target_size=(224,224),\n",
    "                batch_size=batch_size,\n",
    "                color_mode=\"rgb\",\n",
    "                class_mode=\"categorical\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da617ed-d1ff-45a3-9f1c-0bdccf06e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images and labels from the training generator\n",
    "images, labels = next(train_generator)\n",
    "\n",
    "# Display the original and augmented images for the first 5 images\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(5):\n",
    "    # Original Image\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(f'Augmented')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Augmented Image\n",
    "    augmented_image = train_datagen.random_transform(images[i])\n",
    "    augmented_image = np.clip(augmented_image, 0, 1)  # Clip values to [0, 1] range\n",
    "    \n",
    "    plt.subplot(2, 5, i + 6)\n",
    "    plt.imshow(augmented_image)\n",
    "    plt.title(f'Original')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b1b8c",
   "metadata": {
    "papermill": {
     "duration": 0.018044,
     "end_time": "2023-11-24T06:17:08.460436",
     "exception": false,
     "start_time": "2023-11-24T06:17:08.442392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0234a94c",
   "metadata": {
    "papermill": {
     "duration": 0.355014,
     "end_time": "2023-11-24T06:17:08.821329",
     "exception": false,
     "start_time": "2023-11-24T06:17:08.466315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NumberofClass, activation='softmax'))\n",
    "\n",
    "# Use an adaptive learning rate such as Adam\n",
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Implement data augmentation and create generator objects\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Adjust the batch_size and target_size based on your dataset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator) // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator) // validation_generator.batch_size,\n",
    "    class_weight={0: 1, 1: 1.5}  # Adjust the class weights based on your dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778892f",
   "metadata": {
    "papermill": {
     "duration": 0.030146,
     "end_time": "2023-11-24T06:17:08.857295",
     "exception": false,
     "start_time": "2023-11-24T06:17:08.827149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b3fdd",
   "metadata": {
    "papermill": {
     "duration": 0.077259,
     "end_time": "2023-11-24T06:17:08.940641",
     "exception": false,
     "start_time": "2023-11-24T06:17:08.863382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921dda0",
   "metadata": {
    "papermill": {
     "duration": 420.214689,
     "end_time": "2023-11-24T06:24:09.164966",
     "exception": false,
     "start_time": "2023-11-24T06:17:08.950277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data = val_generator,\n",
    "                    batch_size = 108,\n",
    "                    epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39b61d-d042-49df-aff5-f4e40cf42d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for fake vs real classification\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(history.history['accuracy'], 'go--', label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], 'ro--', label='Validation Accuracy')\n",
    "\n",
    "plt.title('Training and Validation Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39ebea-81dc-4ee0-bffd-241dbc3c3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for loss vs val_loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(history.history['loss'], 'go--', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], 'ro--', label='Validation Loss')\n",
    "\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9d3bd-fe8b-4288-97eb-7ca644bc3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator.reset()\n",
    "\n",
    "# Use model.evaluate to get predictions\n",
    "results = model.evaluate(val_generator, steps=len(val_generator), verbose=0)\n",
    "\n",
    "# 'results' will contain loss and accuracy\n",
    "loss, accuracy = results\n",
    "\n",
    "print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce9576-dead-46f1-bba6-e020bab75880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the custom image\n",
    "custom_img_path = 'C:/Users/12499/Pictures/Screenshots/Screenshot 2023-11-27 225217.png'  # Replace with your image path\n",
    "custom_img = load_img(custom_img_path, target_size=(224, 224))\n",
    "\n",
    "# Convert the image to a NumPy array and normalize\n",
    "custom_img_array = img_to_array(custom_img) / 255.0\n",
    "custom_img_array = np.expand_dims(custom_img_array, axis=0)  # Add an extra dimension for batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f94d1-c0f9-4d9b-bfde-3c9d0948941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(custom_img_array)\n",
    "\n",
    "# Get the class with the highest probability\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Map the class index to the corresponding class label (real or fake)\n",
    "class_labels = {0: 'Real', 1: 'Fake'}\n",
    "predicted_label = class_labels[predicted_class]\n",
    "\n",
    "print(f'The predicted class is: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae36acc4-799a-401d-abc9-8271016f620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the custom image\n",
    "custom_img_path = 'C:/Users/12499/Pictures/Screenshots/Screenshot 2023-11-27 183138.png'# Replace with your image path\n",
    "custom_img = load_img(custom_img_path, target_size=(224, 224))\n",
    "\n",
    "# Convert the image to a NumPy array and normalize\n",
    "custom_img_array = img_to_array(custom_img) / 255.0\n",
    "custom_img_array = np.expand_dims(custom_img_array, axis=0)  # Add an extra dimension for batch size\n",
    "# Make predictions\n",
    "predictions = model.predict(custom_img_array)\n",
    "\n",
    "# Get the class with the highest probability\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Map the class index to the corresponding class label (real or fake)\n",
    "class_labels = {0: 'Real', 1: 'Fake'}\n",
    "predicted_label = class_labels[predicted_class]\n",
    "\n",
    "print(f'The predicted class is: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f4621-cf77-4074-bd0e-3c90e3960338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2825392,
     "sourceId": 4872904,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "venv311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 444.784695,
   "end_time": "2023-11-24T06:24:12.946685",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-24T06:16:48.161990",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
